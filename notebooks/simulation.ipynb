{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1.])\n",
      "tensor([-1., -1., -1., -1.])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n",
      "tensor([[1., 0., 0., 0.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 0., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "p = 0.5\n",
    "\n",
    "muX_0 = torch.ones(2)\n",
    "muZ_0 = torch.ones(2)\n",
    "mu_0 = torch.cat([muX_0, muZ_0])\n",
    "print(mu_0)\n",
    "\n",
    "muX_1 = -torch.ones(2)\n",
    "muZ_1 = -torch.ones(2)\n",
    "mu_1 = torch.cat([muX_1, muZ_1])\n",
    "print(mu_1)\n",
    "\n",
    "cov = 0.0\n",
    "CXX_0 = torch.eye(2)\n",
    "CZZ_0 = torch.eye(2)\n",
    "CZX_0 = cov * torch.eye(2)\n",
    "CXZ_0 = CZX_0.T\n",
    "C_0 = torch.cat(\n",
    "    [\n",
    "        torch.cat([CXX_0, CXZ_0], dim=1),\n",
    "        torch.cat([CZX_0, CZZ_0], dim=1)\n",
    "    ], dim=0\n",
    ")\n",
    "print(C_0)\n",
    "\n",
    "\n",
    "CXX_1 = torch.eye(2)\n",
    "CZZ_1 = torch.eye(2)\n",
    "CZX_1 = cov * torch.eye(2)\n",
    "CXZ_1 = CZX_1.T\n",
    "C_1 = torch.cat(\n",
    "    [\n",
    "        torch.cat([CXX_1, CXZ_1], dim=1),\n",
    "        torch.cat([CZX_1, CZZ_1], dim=1)\n",
    "    ], dim=0\n",
    ")\n",
    "print(C_1)\n",
    "\n",
    "mvn_0 = MultivariateNormal(loc=mu_0, covariance_matrix=C_0)\n",
    "mvn_1 = MultivariateNormal(loc=mu_1, covariance_matrix=C_1)\n",
    "\n",
    "mvnX_0 = MultivariateNormal(loc=muX_0, covariance_matrix=CXX_0)\n",
    "mvnX_1 = MultivariateNormal(loc=muX_1, covariance_matrix=CXX_1)\n",
    "\n",
    "mvnZ_0 = MultivariateNormal(loc=muZ_0, covariance_matrix=CZZ_0)\n",
    "mvnZ_1 = MultivariateNormal(loc=muZ_1, covariance_matrix=CZZ_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_Z_given(x, p, n_samples=10, seed=123):\n",
    "    dist_0 = MultivariateNormal(loc=muZ_0 + CZX_0 @ torch.linalg.solve(CXX_0, x - muX_0), covariance_matrix=CZZ_0 - CZX_0 @ torch.linalg.solve(CXX_0, CXZ_0))\n",
    "    dist_1 = MultivariateNormal(loc=muZ_1 + CZX_1 @ torch.linalg.solve(CXX_1, x - muX_1), covariance_matrix=CZZ_1 - CZX_1 @ torch.linalg.solve(CXX_1, CXZ_1))\n",
    "    n1 = int(n_samples * p)\n",
    "    n0 = n_samples - n1\n",
    "    torch.manual_seed(seed)\n",
    "    return torch.cat([dist_0.rsample((n0,)), dist_1.rsample((n1,))], dim=0)\n",
    "\n",
    "def compute_pxz(x, z, p):\n",
    "    v = torch.cat([x, z], axis=1)\n",
    "    lp_1 = math.log(p)\n",
    "    lp_0 = math.log(1 - p)\n",
    "    numer = mvn_1.log_prob(v) + lp_1\n",
    "    denom = (mvn_1.log_prob(v) + lp_1) * (mvn_0.log_prob(v) + lp_0)\n",
    "    return torch.exp(numer - denom)\n",
    "\n",
    "def compute_pz(z, p):\n",
    "    lp_1 = math.log(p)\n",
    "    lp_0 = math.log(1 - p)\n",
    "    numer = mvnZ_1.log_prob(z) + lp_1\n",
    "    denom = (mvnZ_1.log_prob(z) + lp_1) * (mvnZ_0.log_prob(z) + lp_0)\n",
    "    return torch.exp(numer - denom)\n",
    "\n",
    "def compute_px(x, p):\n",
    "    lp_1 = math.log(p)\n",
    "    lp_0 = math.log(1 - p)\n",
    "    numer = mvnX_1.log_prob(x) + lp_1\n",
    "    denom = (mvnX_1.log_prob(x) + lp_1) * (mvnX_0.log_prob(x) + lp_0)\n",
    "    return torch.exp(numer - denom)\n",
    "\n",
    "def compute_cmi(n_samples, p, tol=1e-10, seed=123):\n",
    "\n",
    "    # compute test data\n",
    "    torch.manual_seed(seed)\n",
    "    n1 = int(n_samples * p)\n",
    "    n0 = n_samples - n1\n",
    "    v = torch.cat([mvn_0.rsample((n0,)), mvn_1.rsample((n1,))], dim=0)\n",
    "    x = v[:, :len(muX_0)]\n",
    "    z = v[:, len(muX_0):]\n",
    "    v_ = torch.cat([mvn_0.rsample((n0,)), mvn_1.rsample((n1,))], dim=0)\n",
    "    z_ =  v_[:, len(muX_0):]\n",
    "\n",
    "    pxz = torch.clamp(compute_pxz(x, z, p), min=tol, max=1.0)\n",
    "    pz = torch.clamp(compute_pz(z_, p), min=tol, max=1.0)\n",
    "\n",
    "    # possible numerical issue from exp then log.\n",
    "    H_XZ = (-(pxz) * torch.log(pxz) - (1 - pxz) * torch.log(1 - pxz)).mean()\n",
    "    H_Z = (-(pz) * torch.log(pz) - (1 - pz) * torch.log(1 - pz)).mean()\n",
    "\n",
    "    return H_Z - H_XZ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10\n",
    "n1 = int(n_samples * p)\n",
    "n0 = n_samples - n1\n",
    "v = torch.cat([mvn_0.rsample((n0,)), mvn_1.rsample((n1,))], dim=0)\n",
    "x = v[:, :len(muX_0)]\n",
    "z = v[:, len(muX_0):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.5365e-07)\n",
      "tensor(1.5365e-07)\n",
      "tensor(1.5365e-07)\n",
      "tensor(1.5365e-07)\n",
      "tensor(1.5365e-07)\n"
     ]
    }
   ],
   "source": [
    "n_samples = 100000\n",
    "for i in range(5):\n",
    "    print(compute_cmi(n_samples, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
