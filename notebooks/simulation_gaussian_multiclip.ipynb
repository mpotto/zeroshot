{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a93e1eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.distributions.multivariate_normal import MultivariateNormal\n",
    "from torch.distributions import Binomial\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4a60189c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_distributions(setting):\n",
    "    # Embedding dimension\n",
    "    d = setting[\"d\"]\n",
    "    a = setting[\"a\"]\n",
    "    b = setting[\"b\"]\n",
    "    rho = setting[\"rho\"]\n",
    "\n",
    "    # Mean\n",
    "    muX_0, muX_1 = setting[\"muX_0\"], setting[\"muX_1\"]\n",
    "    \n",
    "    muZ_0, muZ_1 = rho * muX_0 / b, rho * muX_1 / b\n",
    "    muW_0, muW_1 = rho * muX_0 / a, rho * muX_1 / a\n",
    "\n",
    "    # Covariance\n",
    "    CXX_0, CXX_1 = torch.eye(d), torch.eye(d)\n",
    "    CZZ_0, CZZ_1 = torch.eye(d), torch.eye(d)\n",
    "    CWW_0, CWW_1 = torch.eye(d), torch.eye(d)\n",
    "\n",
    "    CXW_0, CXW_1 = a * torch.eye(d), a * torch.eye(d)\n",
    "    CXZ_0, CXZ_1 = b * torch.eye(d), b * torch.eye(d)\n",
    "    \n",
    "    # rho = 1 satisfies the conditional independence\n",
    "    CZW_0, CZW_1 = a/b * torch.eye(d), rho * a/b * torch.eye(d)  \n",
    "\n",
    "    params = (muX_0, muX_1, muZ_0, muZ_1, muW_0, muW_1, \n",
    "              CXX_0, CXX_1, CZZ_0, CZZ_1, CWW_0, CWW_1, \n",
    "              CXW_0, CXW_1, CXZ_0, CXZ_1, CZW_0, CZW_1)\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05ee2c0",
   "metadata": {},
   "source": [
    "### Direct Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d85579ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lpx(x, mvnX_0, mvnX_1, p):\n",
    "    lp_1 = math.log(p)\n",
    "    lp_0 = math.log(1 - p)\n",
    "    numer = mvnX_1.log_prob(x) + lp_1\n",
    "    denom = torch.logsumexp(torch.stack([mvnX_1.log_prob(x) + lp_1, mvnX_0.log_prob(x) + lp_0]), dim=0)\n",
    "    return numer - denom"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece41f2",
   "metadata": {},
   "source": [
    "### Indirect Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc2eb587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b(w)\n",
    "def compute_lpw(w, mvnW_0, mvnW_1, p):\n",
    "    lp_1 = math.log(p)\n",
    "    lp_0 = math.log(1 - p)\n",
    "    numer = mvnW_1.log_prob(w) + lp_1\n",
    "    denom = torch.logsumexp(torch.stack([mvnW_1.log_prob(w) + lp_1, mvnW_0.log_prob(w) + lp_0]), dim=0)\n",
    "    return numer - denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "338dbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a(z)\n",
    "\n",
    "def compute_lpz(z, mvnZ_0, mvnZ_1, p):\n",
    "    lp_1 = math.log(p)\n",
    "    lp_0 = math.log(1 - p)\n",
    "    numer = mvnZ_1.log_prob(z) + lp_1\n",
    "    denom = torch.logsumexp(torch.stack([mvnZ_1.log_prob(z) + lp_1, mvnZ_0.log_prob(z) + lp_0]), dim=0)\n",
    "    return numer - denom\n",
    "\n",
    "\n",
    "def sample_W_given(z, p, setting, n_samples=1000, seed=123):\n",
    "    muX_0, muX_1, muZ_0, muZ_1, muW_0, muW_1, CXX_0, CXX_1, CZZ_0, CZZ_1, CWW_0, CWW_1, CXW_0, CXW_1, CXZ_0, CXZ_1, CZW_0, CZW_1 = generate_distributions(setting)\n",
    "    \n",
    "    dist_0 = MultivariateNormal(loc=muW_0 + CZW_0 @ torch.linalg.solve(CZZ_0, z-muZ_0), covariance_matrix=CWW_0 - CZW_0 @ torch.linalg.solve(CZZ_0, CZW_0))\n",
    "    dist_1 = MultivariateNormal(loc=muW_1 + CZW_1 @ torch.linalg.solve(CZZ_1, z-muZ_1), covariance_matrix=CWW_1 - CZW_1 @ torch.linalg.solve(CZZ_1, CZW_1))\n",
    "\n",
    "    mvnZ_0 = MultivariateNormal(loc=muZ_0, covariance_matrix=CZZ_0)\n",
    "    mvnZ_1 = MultivariateNormal(loc=muZ_1, covariance_matrix=CZZ_1)\n",
    "    binom = Binomial(total_count=n_samples, probs=math.exp(compute_lpz(z, mvnZ_0, mvnZ_1, p)))\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    n1 = binom.sample((1,)).int().item()\n",
    "    n0 = n_samples - n1\n",
    "    return torch.cat([dist_0.rsample((n0,)), dist_1.rsample((n1,))], dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eecd3a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x -> E(a(Z)|X)(x)\n",
    "def sample_Z_given(x, p, setting, n_samples=1000, seed=123):\n",
    "    muX_0, muX_1, muZ_0, muZ_1, muW_0, muW_1, CXX_0, CXX_1, CZZ_0, CZZ_1, CWW_0, CWW_1, CXW_0, CXW_1, CXZ_0, CXZ_1, CZW_0, CZW_1 = generate_distributions(setting)\n",
    "\n",
    "    dist_0 = MultivariateNormal(loc=muZ_0 + CXZ_0 @ torch.linalg.solve(CXX_0, x - muX_0), covariance_matrix=CZZ_0 - CXZ_0 @ torch.linalg.solve(CXX_0, CXZ_0))\n",
    "    dist_1 = MultivariateNormal(loc=muZ_1 + CXZ_1 @ torch.linalg.solve(CXX_1, x - muX_1), covariance_matrix=CZZ_1 - CXZ_1 @ torch.linalg.solve(CXX_1, CXZ_1))\n",
    "\n",
    "    mvnX_0 = MultivariateNormal(loc=muX_0, covariance_matrix=CXX_0)\n",
    "    mvnX_1 = MultivariateNormal(loc=muX_1, covariance_matrix=CXX_1)\n",
    "    binom = Binomial(total_count=n_samples, probs=math.exp(compute_lpx(x, mvnX_0, mvnX_1, p)))\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    n1 = binom.sample((1,)).int().item()\n",
    "    n0 = n_samples - n1\n",
    "    return torch.cat([dist_0.rsample((n0,)), dist_1.rsample((n1,))], dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426608be",
   "metadata": {},
   "source": [
    "### Gaussian Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87053fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_bayes_accuracy(p, x, y, mvnX_0, mvnX_1):\n",
    "    lpx = compute_lpx(x, mvnX_0, mvnX_1, p)\n",
    "    y_pred = (lpx >= math.log(0.5)).int()\n",
    "    return (y == y_pred).sum() / len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45bffe3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_three_stage_accuracy(p, x, y, setting, mvnW_0, mvnW_1, seed=123):\n",
    "    px = []\n",
    "    for x_ in tqdm(x):\n",
    "        pz = []\n",
    "        z = sample_Z_given(x_, p, setting, seed=seed, n_samples=10**2)\n",
    "        for z_ in z:\n",
    "            w = sample_W_given(z_, p, setting, seed=seed, n_samples=10**2)\n",
    "            pz.append(torch.exp(compute_lpw(w, mvnW_0, mvnW_1, p)).mean())\n",
    "        pz = torch.tensor(pz) \n",
    "        px.append(pz.mean())\n",
    "    px = torch.tensor(px)\n",
    "    y_pred = (px >= 0.5).int()\n",
    "    return (y == y_pred).sum()/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6bf05157",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gaussian_experiment(p, setting, n_samples, seed=123):\n",
    "    muX_0, muX_1, muZ_0, muZ_1, muW_0, muW_1, CXX_0, CXX_1, CZZ_0, CZZ_1, CWW_0, CWW_1, CXW_0, CXW_1, CXZ_0, CXZ_1, CZW_0, CZW_1 = generate_distributions(setting)\n",
    "    \n",
    "    mu0 = torch.cat([muX_0, muZ_0, muW_0])\n",
    "    mu1 = torch.cat([muX_1, muZ_1, muW_1])\n",
    "    cov0 = torch.cat(\n",
    "        [\n",
    "            torch.cat([CXX_0, CXZ_0, CXW_0], dim=1),\n",
    "            torch.cat([CXZ_0, CZZ_0, CZW_0], dim=1),\n",
    "            torch.cat([CXW_0, CZW_0, CWW_0], dim=1)\n",
    "        ]\n",
    "    )\n",
    "    cov1 = torch.cat(\n",
    "        [\n",
    "            torch.cat([CXX_1, CXZ_1, CXW_1], dim=1),\n",
    "            torch.cat([CXZ_1, CZZ_1, CZW_1], dim=1),\n",
    "            torch.cat([CXW_1, CZW_1, CWW_1], dim=1)\n",
    "        ]\n",
    "    )\n",
    "    mvn0 = MultivariateNormal(loc=mu0, covariance_matrix=cov0) \n",
    "    mvn1 = MultivariateNormal(loc=mu1, covariance_matrix=cov1)\n",
    "\n",
    "    mvnX_0 = MultivariateNormal(loc=muX_0, covariance_matrix=CXX_0)\n",
    "    mvnX_1 = MultivariateNormal(loc=muX_1, covariance_matrix=CXX_1)\n",
    "\n",
    "    mvnZ_0 = MultivariateNormal(loc=muZ_0, covariance_matrix=CZZ_0)\n",
    "    mvnZ_1 = MultivariateNormal(loc=muZ_1, covariance_matrix=CZZ_1)\n",
    "\n",
    "    mvnW_0 = MultivariateNormal(loc=muW_0, covariance_matrix=CWW_0)\n",
    "    mvnW_1 = MultivariateNormal(loc=muW_1, covariance_matrix=CWW_1)\n",
    "\n",
    "    binom = Binomial(total_count=5000, probs=p)\n",
    "    n1 = binom.sample((1,)).int().item()\n",
    "    n0 = 5000 - n1\n",
    "    x = torch.cat([mvnX_0.rsample((n0,)), mvnX_1.rsample((n1,))], dim=0)\n",
    "    y = torch.cat([torch.zeros(n0), torch.ones(n1)]).int()\n",
    "    acc1 = compute_bayes_accuracy(p, x, y, mvnX_0, mvnX_1)\n",
    "\n",
    "    # compute accuracy (two stage/indirect)\n",
    "    binom = Binomial(total_count=n_samples, probs=p)\n",
    "    torch.manual_seed(seed)\n",
    "    n1 = binom.sample((1,)).int().item()\n",
    "    n0 = n_samples - n1\n",
    "    x = torch.cat([mvnX_0.rsample((n0,)), mvnX_1.rsample((n1,))], dim=0)\n",
    "    y = torch.cat([torch.zeros(n0), torch.ones(n1)]).int()\n",
    "    acc2 = compute_three_stage_accuracy(p, x, y, setting, mvnW_0, mvnW_1, seed=seed)\n",
    "\n",
    "    return acc1.item(), acc2.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "817e4b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "a = -0.1\n",
    "b = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9365d6f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.07it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7531999945640564, 0.550000011920929)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting = {\n",
    "    \"muX_0\": torch.ones(d)/2,\n",
    "    \"muX_1\": -torch.ones(d)/2,\n",
    "    \"d\": d,\n",
    "    \"a\": a,\n",
    "    \"b\": b,\n",
    "    \"rho\": 0.0\n",
    "}\n",
    "\n",
    "run_gaussian_experiment(0.5, setting, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b55ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:06<00:00,  3.08it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.926800012588501, 0.949999988079071)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "setting = {\n",
    "    \"muX_0\": torch.ones(d)/2,\n",
    "    \"muX_1\": -torch.ones(d)/2,\n",
    "    \"d\": d,\n",
    "    \"a\": a,\n",
    "    \"b\": b,\n",
    "    \"rho\": 1.0\n",
    "}\n",
    "\n",
    "run_gaussian_experiment(0., setting, 20, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "zsp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
